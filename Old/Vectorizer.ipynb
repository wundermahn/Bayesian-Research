{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn, string, numpy as np, time, pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes numbers from an array\n",
    "def remove_nums(arr): \n",
    "    # Declare a regular expression\n",
    "    pattern = '[0-9]'  \n",
    "    # Remove the pattern, which is a number\n",
    "    arr = [re.sub(pattern, '', i) for i in arr]    \n",
    "    # Return the array with numbers removed\n",
    "    return arr\n",
    "\n",
    "# This function cleans the passed in paragraph and parses it\n",
    "def get_words(para, stem):   \n",
    "    # Create a set of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Split it into lower case    \n",
    "    lower = para.lower().split()\n",
    "    # Remove punctuation\n",
    "    no_punctuation = (nopunc.translate(str.maketrans('', '', string.punctuation)) for nopunc in lower)\n",
    "    # Remove integers\n",
    "    no_integers = remove_nums(no_punctuation)\n",
    "    # Remove stop words\n",
    "    dirty_tokens = (data for data in no_integers if data not in stop_words)\n",
    "    # Ensure it is not empty\n",
    "    tokens = [data for data in dirty_tokens if data.strip()]\n",
    "    # Ensure there is more than 1 character to make up the word\n",
    "    tokens = [data for data in tokens if len(data) > 1]\n",
    "       \n",
    "    if stem == True:\n",
    "        # Perform stemming\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        return stemmed_tokens\n",
    "    \n",
    "    else:\n",
    "        # Return the tokens\n",
    "        return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(df['Text'])\n",
    "corpus = s.apply(lambda s: ' '.join(get_words(s, True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='unicode')\n",
    "count_vectorizer = CountVectorizer(strip_accents='unicode')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "count = count_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(data=tfidf.todense(), columns=tfidf_vectorizer.get_feature_names())\n",
    "count_df = pd.DataFrame(data=count.todense(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_csv('C:\\\\Users\\\\Kelly\\\\Desktop\\\\tfidf.csv')\n",
    "count_df.to_csv('C:\\\\Users\\\\Kelly\\\\Desktop\\\\count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Style: TFIDF | GaussianNB | Score: 0.654\n",
      "Count Style: TFIDF | MultinomialNB | Score: 0.8589333333333333\n",
      "Count Style: TFIDF | ComplementNB | Score: 0.8589333333333333\n",
      "Count Style: TFIDF | BernoulliNB | Score: 0.8446666666666667\n",
      "Count Style: CountDF | GaussianNB | Score: 0.6509333333333334\n",
      "Count Style: CountDF | MultinomialNB | Score: 0.8601333333333333\n",
      "Count Style: CountDF | ComplementNB | Score: 0.8592\n",
      "Count Style: CountDF | BernoulliNB | Score: 0.8449333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(count_df, classes, test_size=0.3, random_state=np.random.randint(1,100))\n",
    "classifiers = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Count Style: TFIDF | {} | Score: {}\".format(str(clf.__class__.__name__), clf.score(X_test, y_test)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, classes, test_size=0.3, random_state=np.random.randint(1,100))\n",
    "classifiers = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Count Style: CountDF | {} | Score: {}\".format(str(clf.__class__.__name__), clf.score(X_test, y_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(list(count_df['aaa']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = count_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-24-09a9204189dc>\", line 2, in <module>\n",
      "    new_df[col] = new_df.sum(axis=1)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\", line 11176, in stat_func\n",
      "    return self._reduce(\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\", line 7911, in _reduce\n",
      "    values = self.values\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\", line 5487, in values\n",
      "    return self._data.as_array(transpose=self._AXIS_REVERSED)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 830, in as_array\n",
      "    arr = mgr._interleave()\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 854, in _interleave\n",
      "    result[rl.indexer] = blk.get_values(dtype)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\kelly\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 746, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for col in new_df.columns:\n",
    "    new_df[col] = new_df.sum(axis=1)\n",
    "\n",
    "print(new_df.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
